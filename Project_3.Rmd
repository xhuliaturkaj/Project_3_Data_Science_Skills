---
title: 'Project 3: Best Skills for a Data Scientist'
author: "Folorunsho Atanda, Xhulia Turkaj, Ron Balaban"
date: "2023-10-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


#### Our project is guided by a pivotal question: ***"What are the most crucial data science skills?"*** To answer this question effectively, we have chosen a method that offers unique insights.



We believe that examining the curricula of top online Master of Data Science programs at 23 universities is an ideal approach. These programs are meticulously designed to equip students with the skills and knowledge needed to excel in the field. By scrutinizing what these respected institutions prioritize, we gain a deep understanding of the skills that form the backbone of data science success.


We employed web scraping techniques to automate the extraction of data, capturing general information about the top 23 online Masters in Data Science programs. This data forms the foundation of the first table in our relational database.

From FORTUNE EDUCATION's website, we extracted the university's name, location, credit cost, and GRE requirements. While examining the URLs associated with the rankings, we discovered that some led to different programs within the same university. To address this, we manually retrieved the URLs for each program's overview website and then integrated them with the remaining information gathered through web scraping. 


#-------------------------------------------------------------------------------
# libraries
```{r}
library(data.table)
library(tidyverse)
library(rvest) #HTML
library(jsonlite) #JSON 
library(xml2) #XML
library(tm)
library(knitr)
library(stringr)
library(RCurl)
```

#-------------------------------------------------------------------------------
# Functions used

```{r}
# function to scrap info from the website used
scrapped_data <- function(data, css_string, regex_string = ".*"){
  data %>% 
    html_elements(css_string) %>% 
    html_text() %>% 
    str_extract(regex_string)
}
```

#-------------------------------------------------------------------------------
# Scraping information on schools
```{r}
url <- "https://fortune.com/education/information-technology/best-online-masters-in-data-science/"
html <- read_html(url)

school_names <- html %>% 
  scrapped_data("fully-clickable , .card-row:nth-child(1) h2", "([a-zA-Z]+\ ?){1,}")

school_location <- html %>% 
  scrapped_data(".card-row:nth-child(1) .text-medium", ".*")

acceptance_rate <- html %>% 
  scrapped_data(".footer:nth-child(3) .col-xxs-6:nth-child(1) .value", ".*")

gre_required <- html %>% 
  scrapped_data(".col-xxs-6:nth-child(4) .value", ".*")

cost_per_credit <- html %>% 
  scrapped_data(".col-xxs-6:nth-child(3) .value", ".*")

avg_work_experience_required <- html %>% 
  scrapped_data(".footer:nth-child(3) .col-xxs-6:nth-child(2) .value", ".*") %>% 
  str_replace_all("DNP", "Did not state")

school_info <- tibble(
  school_names, 
  school_location, 
  acceptance_rate, 
  gre_required,
  cost_per_credit,
  avg_work_experience_required,
  )

school_info
```
#-------------------------------------------------------------------------------


# Scraping data on skills you gain by the programs by creating a function that scrapes the text data from each URL and given CSS selector 
# Here we created  a list called program data where each element is a list containing a URL and selector
```{r}
program_data <- list(
  list(
    name = "Program 1",
    url = "https://online.usc.edu/programs/master-of-science-in-applied-data-science/",
    selector = "p:nth-child(2)"
  ),
  list(
    name = "Program 2",
    url = "https://ischoolonline.berkeley.edu/cybersecurity/curriculum/data-science-certificate/",
    selector = "p.u--margin-bottom-2:nth-child(2)"
  ),
  list(
    name = "Program 3",
    url = "https://www.baypath.edu/academics/graduate-programs/applied-data-science-ms/",
    selector = "li:nth-child(2)"
),
  list(
    name = "Program 4",
    url = "https://catalog.njit.edu/graduate/computing-sciences/computer-science/ms/index.html",
    selector = "td:nth-child(2)"
  ),
  list(
    name = "Program 5",
    url = "https://www.clemson.edu/graduate/academics/ms-dsa/academics.html",
    selector = "td:nth-child(4) , td:nth-child(3), tr:nth-child(2) td:nth-child(2)"
  ),
  list(
    name = "Program 6",
    url = "https://bulletin.iit.edu/graduate/colleges/computing/applied-mathematics/master-data-science/#programrequirementstext",
    selector = "td:nth-child(2)"
  ),
  list(
    name = "Program 7",
    url = "https://osuonline.okstate.edu/programs/graduate/business-analytics-master-of-science.html",
    selector = ".intro-with-media__caption"
  ),
  list(
    name = "Program 8",
    url = "https://www.depts.ttu.edu/rawlsbusiness/graduate/ms/datascience/",
    selector = ".curr-info"
  ),
  list(
    name = "Program 9",
    url = "https://dsa.missouri.edu/masters-program/",
    selector = ".shortcode_pb"
  ),
  list(
    name = "Program 10",
    url = "https://www.msol.ucla.edu/data-science-engineering/",
    selector = c(".order-lg-1", ".mb-0")
  )
)


#-------------------------------------------------------------------------------
# List of our keywords
searchTerms <- getURL("https://raw.githubusercontent.com/xhuliaturkaj/Project_3_Data_Science_Skills/main/Keywords.csv") %>%
  read_csv(col_names = FALSE, trim_ws = TRUE) %>%
  # remove newline
  mutate(X1 = str_replace_all(X1, "\\n", "")) %>%
  # convert to vector
  pull(1)
#-------------------------------------------------------------------------------


# Define a function to scrape skills from a program data entry
scrape_skills <- function(program_data_entry) {
  webpage <- read_html(program_data_entry$url)
  skills <- webpage %>%
    html_nodes(program_data_entry$selector) %>%
    html_text(trim = TRUE)
  return(skills)
}

# Scrape skills for each program in program_data
scraped_skills <- lapply(program_data, scrape_skills)
print(scraped_skills)

#-------------------------------------------------------------------------------
# The raw text for the programs
text_for_program_1 <- paste(scraped_skills[[1]], collapse = " ")
text_for_program_2 <- paste(scraped_skills[[2]], collapse = " ")
text_for_program_3 <- paste(scraped_skills[[3]], collapse = " ")
text_for_program_4 <- paste(scraped_skills[[4]], collapse = " ")
text_for_program_5 <- paste(scraped_skills[[5]], collapse = " ")
text_for_program_6 <- paste(scraped_skills[[6]], collapse = " ")
text_for_program_7 <- paste(scraped_skills[[7]], collapse = " ")
text_for_program_8 <- paste(scraped_skills[[8]], collapse = " ")
text_for_program_9 <- paste(scraped_skills[[9]], collapse = " ")
text_for_program_10 <-paste(scraped_skills[[10]], collapse = " ")


#Create one object that stores the combined text
combined_text <- paste(text_for_program_1, text_for_program_2, text_for_program_3,text_for_program_4,text_for_program_5, text_for_program_6, text_for_program_7, text_for_program_8, text_for_program_9, text_for_program_10, collapse = " ")

print(combined_text)
```


#-------------------------------------------------------------------------------
# Graph to show the frequency of desired data science skills from the various programs
```{r}
element_count <- str_extract_all(combined_text, searchTerms) %>% 
  lapply(function(x) length(x))

searchTerms_table <- as_tibble(do.call(rbind, lapply(searchTerms, function(x) c(Key_Skills = x))))
element_count_table <- as_tibble(do.call(rbind, lapply(element_count, function(x) c(Count = x))))

frequency_table <- tibble(searchTerms_table, element_count_table)

# Remove those with no appearances
cleaned_frequency_table <- frequency_table %>% 
  filter(Count > 0)

cleaned_frequency_table %>%
  ggplot(aes(x = Key_Skills, y = Count)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab('Skill') + ylab('Frequency') + labs(title = "Frequency of Data Science Skills") + theme(legend.position = "none") +
  geom_text(aes(label = Count), hjust = -0.25, color = "black")

```


